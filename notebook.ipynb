{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live-stock detection (DeepForest)\n",
    "## Context\n",
    "### Purpose\n",
    "Implement and finetune a prebuilt Deep Learning model to detect live-stock in airborne imagery.\n",
    "\n",
    "\n",
    "### Modelling Approach\n",
    "The [live-stock detection model](https://huggingface.co/weecology/deepforest-livestock) from the latest version (v1.4.1) of the [DeepForest](https://deepforest.readthedocs.io/en/latest/) Deep Learning model is used to predict bounding boxes corresponding to cattle from airborn RGB images.\n",
    "\n",
    "The prebuilt model was trained on a [limited dataset](https://new.wildlabs.net/discussion/global-model-livestock-detection-airborne-imagery-data-applications-and-needs). According to the package's documentation, \"the prebuilt models will always be improved by adding data from the target area\". As such, this notebook will explore the improvement in the model's performance in live-stock detection from fine-tuning on local data.\n",
    "\n",
    "### Description\n",
    "This notebook will explore the capabilities of the DeepForest package. In particular, it will demonstrate how to:\n",
    "\n",
    "- Detect live-stock in airborne imagery using the prebuilt live-stock detection model.\n",
    "- Fine-tune the model using a novel publicly-available dataset.\n",
    "- Evaluate the the model's performance before and after fine-tuning.\n",
    "\n",
    "### Highlights\n",
    "The prebuilt model was trained on 2585 training and 808 validation annotations, and its performance metrics on the test set (subset of images excluded from training/validation sets) showed substantial gains:\n",
    "\n",
    "Box Recall: Improved from 0.4405 to 0.9535.\n",
    "Box Precision: Improved from 0.5826 to 0.8587.\n",
    "Mean IoU: Improved from 0.3135 to 0.6571.\n",
    "\n",
    "### Contributions\n",
    "#### Notebook\n",
    "* Cameron Appel (author), Queen Mary University of London, @camappel\n",
    "\n",
    "#### Modelling codebase\n",
    "* Ben Weinstein (maintainer & developer), University of Florida, @bw4sz\n",
    "* Henry Senyondo (support maintainer), University of Florida, @henrykironde\n",
    "* Ethan White (PI and author), University of Florida, @weecology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install deepforest==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import intake\n",
    "import xmltodict\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from deepforest import main\n",
    "from deepforest.visualize import plot_predictions\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import torch\n",
    "\n",
    "from shapely.geometry import box\n",
    "from skimage.exposure import equalize_hist\n",
    "\n",
    "import pooch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set project structure\n",
    "*The cell below creates a separate folder to save the notebook outputs. This facilitates the reader to inspect inputs/outputs stored within a defined destination folder.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "notebook_folder = './notebook'\n",
    "if not os.path.exists(notebook_folder):\n",
    "    os.makedirs(notebook_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir = os.path.join(notebook_folder, 'test_data')\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch RGB images from Zenodo\n",
    "\n",
    "Fetch sample images from [Zenodo](https://zenodo.org/records/13851270).\n",
    "\n",
    "Data were sourced from Harvard's publicly accessible [ODjAR Dataverse](https://dataverse.harvard.edu/dataverse/ODjAR). Specifically, G.J. Franke; Sander Mucher, 2021, \"Annotated cows in aerial images for use in deep learning models\", which includes \"a large dataset containing aerial images from fields in Juchowo, Poland and Wageningen, the Netherlands, with annotated cows present in the images using Pascal VOC XML Annotation Format.\"\n",
    "\n",
    "Given that this dataset is stored as a multi-part archive, it was necessary to download and unzip the files separately using `pyunpack`, then distribute the test subset on Zenodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzipped_files = pooch.retrieve(\n",
    "    url=\"doi:10.5281/zenodo.13851270/test_data.zip\",\n",
    "    known_hash=\"6a0a5b48fc9326e97c3cd8bdcabc2bcd131f3755f6ceabbf6976aefbfc87fb00\",\n",
    "    processor=pooch.Unzip(extract_dir=extract_dir),\n",
    "    path=f\".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV (annotations), assuming it's also part of the unzipped files\n",
    "test_path = [file for file in unzipped_files if file.endswith('test.csv')][0]\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main.deepforest()\n",
    "model.load_model(model_name=\"weecology/deepforest-livestock\", revision=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.label_dict = {'cow': 0}  # Assign a unique integer ID to the 'cow' label\n",
    "model.config['gpus'] = '-1'  # Use GPU (set to '0' for the first GPU or '-1' for all GPUs)\n",
    "model.config['workers'] = 0\n",
    "\n",
    "# Set the directory to save the results of the pretrained model\n",
    "baseline_save_dir = os.path.join(notebook_folder, 'baseline_pred_result')\n",
    "os.makedirs(baseline_save_dir, exist_ok=True)\n",
    "\n",
    "# Evaluate the pretrained model on the test set (using test_file)\n",
    "baseline_results = model.evaluate(test_path, os.path.dirname(test_path), iou_threshold=0.4, savedir=baseline_save_dir)\n",
    "\n",
    "print(\"Baseline evaluation complete. Results saved to\", baseline_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline performance\")\n",
    "# Print box recall and precision with clean formatting\n",
    "print(f\"Box Recall: {baseline_results['box_recall']:.4f}\")\n",
    "print(f\"Box Precision: {baseline_results['box_precision']:.4f}\")\n",
    "\n",
    "# Compute and print the mean IoU, rounded to 4 decimal places\n",
    "mean_iou = np.mean(baseline_results['results']['IoU'])\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the test.csv file\n",
    "test_csv_path = os.path.join(extract_dir, \"test.csv\")\n",
    "df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Step 2: Load the image\n",
    "image_name = \"20181001 (88).JPG\"  # The image you want to plot, change this as needed\n",
    "image_path = os.path.join(extract_dir, image_name)\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "image_np = np.array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Filter bounding boxes for the specific image\n",
    "image_boxes = df[df['image_path'] == image_name]\n",
    "\n",
    "# Step 4: Prepare bounding boxes DataFrame for plot_predictions\n",
    "boxes_df = image_boxes[['xmin', 'xmax', 'ymin', 'ymax', 'label']]\n",
    "\n",
    "# Step 5: Plot bounding boxes on the image using deepforest.visualize\n",
    "annotated_image_truth = plot_predictions(image_np, boxes_df, color=(0, 165, 255), thickness=15)\n",
    "\n",
    "# Step 6: Display the image with bounding boxes\n",
    "plt.imshow(annotated_image_truth)\n",
    "plt.axis('off')  # Turn off axis to focus on the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming baseline_results is already available\n",
    "predictions_df = baseline_results['predictions']\n",
    "\n",
    "# Step 2: Filter predicted boxes for the specific image\n",
    "image_predictions = predictions_df[predictions_df['image_path'] == image_name]\n",
    "\n",
    "# Step 3: Prepare bounding boxes DataFrame for plot_predictions\n",
    "# Use xmin, ymin, xmax, ymax and label columns from predictions\n",
    "boxes_df = image_predictions[['xmin', 'xmax', 'ymin', 'ymax', 'label']]\n",
    "\n",
    "# Step 4: Plot bounding boxes on the image using deepforest.visualize\n",
    "annotated_image_base = plot_predictions(image_np, boxes_df, color=(0, 165, 255), thickness=15)\n",
    "\n",
    "# Step 5: Display the image with bounding boxes\n",
    "plt.imshow(annotated_image_base)\n",
    "plt.axis('off')  # Turn off axis to focus on the image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "We then trained the model and uploaded to HuggingFace using the following code:\n",
    "\n",
    "```python\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "output_dir = os.path.join(notebook_folder, 'data')\n",
    "test_dir = os.path.join(notebook_folder, 'test_data')\n",
    "\n",
    "train_file = os.path.join(output_dir, \"train.csv\")\n",
    "valid_file = os.path.join(output_dir, \"valid.csv\")\n",
    "test_file = os.path.join(test_dir, \"test.csv\")\n",
    "\n",
    "model.label_dict = {'cow': 0}  # Rename label\n",
    "\n",
    "# Configure the model for GPU usage and set the CSV file paths\n",
    "model.config['gpus'] = '-1'  # Use GPU (set to '0' for the first GPU or '-1' for all GPUs)\n",
    "model.config[\"train\"][\"csv_file\"] = train_file  # Path to training CSV\n",
    "model.config[\"train\"][\"root_dir\"] = os.path.dirname(train_file)  # Root directory for training images\n",
    "model.config[\"score_thresh\"] = 0.4  # Set score threshold\n",
    "model.config[\"train\"]['epochs'] = 5  # Number of epochs\n",
    "model.config[\"validation\"][\"csv_file\"] = valid_file  # Path to validation CSV\n",
    "model.config[\"validation\"][\"root_dir\"] = os.path.dirname(valid_file)  # Root directory for validation images\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='box_recall', patience=2, mode='max')\n",
    "\n",
    "callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/',  # Directory to save checkpoints\n",
    "    monitor='box_recall',  # Metric to monitor\n",
    "    mode=\"max\",  # Save when the metric is maximized\n",
    "    save_top_k=3,  # Save the top 3 checkpoints\n",
    "    filename=\"box_recall-{epoch:02d}-{box_recall:.2f}\"  # File name format for checkpoints\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='logdir/')\n",
    "\n",
    "model.create_trainer(logger=TensorBoardLogger(save_dir='logdir/'),\n",
    "                                  callbacks=[callback, early_stopping])\n",
    "\n",
    "model.trainer.fit(model)\n",
    "\n",
    "checkpoint_dir = './drive/MyDrive/notebook/checkpoints_ckpt'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Save the model checkpoint as .ckpt\n",
    "checkpoint_path = \"{}/finetuned_checkpoint.ckpt\".format(checkpoint_dir)\n",
    "\n",
    "# Save the checkpoint after training using PyTorch Lightning's save_checkpoint method\n",
    "model.trainer.save_checkpoint(checkpoint_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the finetuned model checkpoint from Hugging Face\n",
    "ckpt_path = hf_hub_download(\n",
    "    repo_id=\"camappel/deepforest-livestock\",  # Replace with your Hugging Face repo ID\n",
    "    filename=\"finetuned_checkpoint.ckpt\"     # The .ckpt file you uploaded\n",
    ")\n",
    "\n",
    "# Load the model checkpoint correctly using the class, not an instance\n",
    "model = main.deepforest.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "print(\"Finetuned model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate finetuned performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.label_dict = {'cow': 0}  # Assign a unique integer ID to the 'cow' label\n",
    "model.config['gpus'] = '-1'  # Use GPU (set to '0' for the first GPU or '-1' for all GPUs)\n",
    "model.config['workers'] = 0\n",
    "\n",
    "# Set the directory to save the results of the pretrained model\n",
    "finetuned_save_dir = os.path.join(notebook_folder, 'finetuned_pred_result')\n",
    "os.makedirs(finetuned_save_dir, exist_ok=True)\n",
    "\n",
    "# Evaluate the pretrained model on the test set (using test_file)\n",
    "finetuned_results = model.evaluate(test_path, os.path.dirname(test_path), iou_threshold=0.4, savedir=finetuned_save_dir)\n",
    "\n",
    "print(\"Finetuned evaluation complete. Results saved to\", finetuned_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finetuned performance\")\n",
    "# Print box recall and precision with clean formatting\n",
    "print(f\"Box Recall: {finetuned_results['box_recall']:.4f}\")\n",
    "print(f\"Box Precision: {finetuned_results['box_precision']:.4f}\")\n",
    "\n",
    "# Compute and print the mean IoU, rounded to 4 decimal places\n",
    "mean_iou = np.mean(finetuned_results['results']['IoU'])\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming baseline_results is already available\n",
    "predictions_df = finetuned_results['predictions']\n",
    "\n",
    "# Step 2: Filter predicted boxes for the specific image\n",
    "image_predictions = predictions_df[predictions_df['image_path'] == image_name]\n",
    "\n",
    "# Step 3: Prepare bounding boxes DataFrame for plot_predictions\n",
    "# Use xmin, ymin, xmax, ymax and label columns from predictions\n",
    "boxes_df = image_predictions[['xmin', 'xmax', 'ymin', 'ymax', 'label']]\n",
    "\n",
    "# Step 4: Plot bounding boxes on the image using deepforest.visualize\n",
    "annotated_image_fine = plot_predictions(image_np, boxes_df, color=(0, 165, 255), thickness=15)\n",
    "\n",
    "# Step 5: Display the image with bounding boxes\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # Create 1 row, 2 column layout\n",
    "\n",
    "# Plot ground truth on the left\n",
    "axs[0].imshow(annotated_image_base)\n",
    "axs[0].set_title(\"Baseline Predictions\")\n",
    "axs[0].axis('off')  # Turn off axis for clarity\n",
    "\n",
    "# Plot predictions on the right\n",
    "axs[1].imshow(annotated_image_fine)\n",
    "axs[1].set_title(\"Finetuned Predictions\")\n",
    "axs[1].axis('off')  # Turn off axis for clarity\n",
    "\n",
    "# Show the side-by-side plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to finetune the DeepForest livestock detection model, with significant performance improvements after fine-tuning for 5 epochs. The model was trained on labelled aerial images of cows from Dataverse (2585 training/808 validation), and its performance metrics on the test set (subset of images excluded from training/validation sets) showed substantial gains:\n",
    "\n",
    "Box Recall: Improved from 0.4405 to 0.9535.\n",
    "Box Precision: Improved from 0.5826 to 0.8587.\n",
    "Mean IoU: Improved from 0.3135 to 0.6571."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional information\n",
    "**Dataset**: Data were sourced from Harvard's publicly accessible [ODjAR Dataverse](https://dataverse.harvard.edu/dataverse/ODjAR). \n",
    "\n",
    "Specifically, G.J. Franke; Sander Mucher, 2021, \"Annotated cows in aerial images for use in deep learning models\", which includes \"a large dataset containing aerial images from fields in Juchowo, Poland and Wageningen, the Netherlands, with annotated cows present in the images using Pascal VOC XML Annotation Format.\"\n",
    "\n",
    "The fine-tuned model was tested on a subset of these data, which is distributed on [Zenodo](https://zenodo.org/records/13851270).\n",
    "\n",
    "**Codebase**: DeepForest [v1.4.1](https://github.com/weecology/DeepForest)\n",
    "\n",
    "**License**: The code in this notebook is licensed under the MIT License. The Environmental Data Science book is licensed under the Creative Commons by Attribution 4.0 license. See further details [here](https://github.com/alan-turing-institute/environmental-ds-book/blob/master/LICENSE.md).\n",
    "\n",
    "**Contact**: If you have any suggestion or report an issue with this notebook, feel free to [create an issue](https://github.com/alan-turing-institute/environmental-ds-book/issues/new/choose) or send a direct message to [environmental.ds.book@gmail.com](mailto:environmental.ds.book@gmail.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "print(f'Last tested: {date.today()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
